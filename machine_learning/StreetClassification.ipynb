{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for putting data into folders based on their labels\n",
    "import csv\n",
    "import shutil\n",
    "train_path = r'C:\\Users\\benja\\Downloads\\HackaTUM_Data\\HackaTUM_Data\\dataset\\hackatum_dataset\\train'\n",
    "#for training data\n",
    "readerhighway = csv.DictReader(open(train_path + r'\\labels.csv'))\n",
    "#create a dictionary with the labels as keys and the filenames as values\n",
    "highway_train = []\n",
    "street_train = []\n",
    "for entry in readerhighway:\n",
    "    if(entry[\"highway\"] ==\"footway\"):\n",
    "        street_train.append(entry[\"image_id\"])\n",
    "    if(entry[\"highway\"] == \"primary\"):\n",
    "        highway_train.append(entry[\"image_id\"])\n",
    "#put the images into the corresponding folders\n",
    "for image in highway_train:\n",
    "    shutil.copy(train_path + \"\\\\\" + image + \".jpg\", train_path + \"\\\\highway\")\n",
    "for image in street_train:\n",
    "    shutil.copy(train_path + \"\\\\\" + image + \".jpg\", train_path + \"\\\\street\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for putting data into folders based on their labels on the validation set\n",
    "val_path = r'C:\\Users\\benja\\Downloads\\HackaTUM_Data\\HackaTUM_Data\\dataset\\hackatum_dataset\\val'\n",
    "readerstreet = csv.DictReader(open(val_path + r'\\labels.csv'))\n",
    "highway_val = []\n",
    "street_val = []\n",
    "for entry in readerstreet:\n",
    "    if(entry[\"highway\"] ==\"footway\"):\n",
    "        street_val.append(entry[\"image_id\"])\n",
    "    if(entry[\"highway\"] == \"primary\"):\n",
    "        highway_val.append(entry[\"image_id\"])\n",
    "for image in highway_val:\n",
    "    shutil.copy(val_path + \"\\\\\" + image + \".jpg\", val_path + \"\\\\highway\")\n",
    "for image in street_val:\n",
    "    shutil.copy(val_path + \"\\\\\" + image + \".jpg\", val_path + \"\\\\street\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries and dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import image\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create training and test objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n",
      "Found 125 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train.flow_from_directory(r\"C:\\Users\\benja\\Downloads\\HackaTUM_Data\\HackaTUM_Data\\dataset\\hackatum_dataset\\train\",\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary')\n",
    "                                         \n",
    "test_dataset = test.flow_from_directory(r\"C:\\Users\\benja\\Downloads\\HackaTUM_Data\\HackaTUM_Data\\dataset\\hackatum_dataset\\val\",\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Convolutional layer and maxpool layer 1\n",
    "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 2\n",
    "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 3\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 4\n",
    "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model.add(keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\benja\\Anaconda3\\envs\\hackatum2022\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\benja\\Anaconda3\\envs\\hackatum2022\\lib\\site-packages\\keras\\utils\\image_utils.py:386\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    384\u001b[0m   color_mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m pil_image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not import PIL.Image. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    387\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mThe use of `load_img` requires PIL.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, io\u001b[39m.\u001b[39mBytesIO):\n\u001b[0;32m    389\u001b[0m   img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "                    steps_per_epoch=16,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filename):\n",
    "    img1 = image.load_img(filename,target_size=(150,150))\n",
    "    \n",
    "    plt.imshow(img1)\n",
    " \n",
    "    Y = image.img_to_array(img1)\n",
    "    \n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    val = model.predict(X)\n",
    "    print(val)\n",
    "    if val == 1:\n",
    "        \n",
    "        plt.xlabel(\"Street\",fontsize=30)\n",
    "        \n",
    "    \n",
    "    elif val == 0:\n",
    "        \n",
    "        plt.xlabel(\"Highway\",fontsize=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('hackatum2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe84377ca08c40919caf500bab92d594d5832025e4d25ecbec8a1e308927f047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
